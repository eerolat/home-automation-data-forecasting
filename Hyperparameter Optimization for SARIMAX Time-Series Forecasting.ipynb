{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter_Optimization_for_SARIMA_Time-Series_Forecasting.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owwf0VcjYI9W",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter Optimization for SARIMA Time-Series Forecasting\n",
        "Tuomas Eerola - 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViCCDwZRgT5S",
        "colab_type": "text"
      },
      "source": [
        "## Download Techila SDK into your Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKRufDtI4ZV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_server_ip = '' #@param {type:\"string\"}\n",
        "my_password = ''  #@param {type: \"string\"}\n",
        "!wget --post-data=\"login=admin&password={my_password}\" --no-check-certificate https://{my_server_ip}/gce_downloadsdk.php -O techilasdk.zip\n",
        "!unzip techilasdk.zip\n",
        "\n",
        "%cd /content/techila/lib/python3\n",
        "!python setup.py install\n",
        "!echo \"JVMPATH=/usr/lib/jvm/default-java/lib/server/libjvm.so\" > /content/techila/lib/TechilaDLL.conf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36XWSAkWgstw",
        "colab_type": "text"
      },
      "source": [
        "## Launch some Techila Workers\n",
        "Run and click the link to launch some Techila Workers. Techila Workers are the compute nodes in your Techila Distributed Computing Engine system that do the actual processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgPnmwJ5g9G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('https://' + my_server_ip + '/gce_deployment.php?step=deploy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezCqjM1RYb3I",
        "colab_type": "text"
      },
      "source": [
        "## Load IoT sensor data and prepare it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yofc6xZfa2G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from urllib.request import urlopen\n",
        "\n",
        "log_url = \"http://eerola.dy.fi/temp/temperature.log\"\n",
        "\n",
        "series_own = pd.read_csv(log_url, sep=\" \", parse_dates=[[0, 1]])\n",
        "series_own.columns=['Date Time', 'SourceInfo1', 'SourceInfo2', 'MeasurementInfo1', 'Temp', 'MeasurementInfo2', 'Measurement2']\n",
        "dropcolumns = ['SourceInfo1', 'SourceInfo2', 'MeasurementInfo1', 'MeasurementInfo2', 'Measurement2']\n",
        "series_own.drop(dropcolumns, inplace=True, axis=1)\n",
        "series_own.set_index('Date Time', inplace=True)\n",
        "\n",
        "series = series_own.reset_index()\n",
        "series = series.drop_duplicates(subset='Date Time', keep='last')\n",
        "series = series.set_index('Date Time')\n",
        "series = series.resample('H').bfill()\n",
        "\n",
        "print (\"Data loading ready.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBydIWwbYlCj",
        "colab_type": "text"
      },
      "source": [
        "## Configure the run settings.\n",
        "\n",
        "Select how much of the IoT sensor data we want to use in the hyperparameter optimization, and other configuration items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgXSNCJCY6NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_number_of_data_points = 100\n",
        "test_data_percentage_of_data_points = 20\n",
        "\n",
        "# When setting run_parallel False, comment out\n",
        "# @techila.distributable() line in the helper functions.\n",
        "run_parallel = True\n",
        "\n",
        "# Grouping more operations in one parallel job can benefit the performance.\n",
        "num_of_operations_per_parallel_job = 20\n",
        "\n",
        "print (\"Ready.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPh-eKFIat69",
        "colab_type": "text"
      },
      "source": [
        "## Introduce the set of SARIMA configs to try.\n",
        "\n",
        "Configuring a SARIMA requires selecting hyperparameters for both the trend and seasonal elements of the series.\n",
        "\n",
        "There are three trend elements that require configuration.\n",
        "\n",
        "They are the same as the ARIMA model; specifically:\n",
        "\n",
        "*   p: Trend autoregression order.\n",
        "*   d: Trend difference order.\n",
        "*   q: Trend moving average order.\n",
        "\n",
        "\n",
        "There are four seasonal elements that are not part of ARIMA that must be configured; they are:\n",
        "\n",
        "*   P: Seasonal autoregressive order.\n",
        "*   D: Seasonal difference order.\n",
        "*   Q: Seasonal moving average order.\n",
        "*   m: The number of time steps for a single seasonal period."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PxV9RJLauFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sarima_configs(seasonal=[0]):\n",
        "  models = list()\n",
        "\n",
        "  p_params = [0, 1, 2]\n",
        "  d_params = [0, 1]\n",
        "  q_params = [0, 1, 2]\n",
        "  t_params = ['n','c','t','ct']\n",
        "  P_params = [0, 1, 2]\n",
        "  D_params = [0, 1]\n",
        "  Q_params = [0, 1, 2]\n",
        "  m_params = seasonal\n",
        "\n",
        "  for p in p_params:\n",
        "    for d in d_params:\n",
        "      for q in q_params:\n",
        "        for t in t_params:\n",
        "          for P in P_params:\n",
        "            for D in D_params:\n",
        "              for Q in Q_params:\n",
        "                for m in m_params:\n",
        "                  cfg = [(p,d,q), (P,D,Q,m), t]\n",
        "                  models.append(cfg)\n",
        "  return models\n",
        "\n",
        "print (\"Ready.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toCPOF0icLYg",
        "colab_type": "text"
      },
      "source": [
        "## Introduce some helper functions.\n",
        "\n",
        "Run this to introduce some helper functions that we will use in this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0idInI8VYmOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if total_number_of_data_points > len(series):\n",
        "  print (\"Error. Reduce total_number_of_data_points.\")\n",
        "elif test_data_percentage_of_data_points >100:\n",
        "  print (\"Error. Reduce test_data_percentage_of_data_points.\")\n",
        "else:\n",
        "  data = series['Temp'].tail(total_number_of_data_points).tolist()\n",
        "  n_test_percentage = test_data_percentage_of_data_points/100\n",
        "  \n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from warnings import catch_warnings\n",
        "from warnings import filterwarnings\n",
        "import techila\n",
        "\n",
        "# one-step sarima forecast\n",
        "def sarima_forecast(history, config):\n",
        "  order, sorder, trend = config\n",
        "\t# define model\n",
        "  model = SARIMAX(history, order=order, seasonal_order=sorder, trend=trend, enforce_stationarity=False, enforce_invertibility=False)\n",
        "\t# fit model\n",
        "  model_fit = model.fit(disp=False)\n",
        "\t# make one step forecast\n",
        "  yhat = model_fit.predict(len(history), len(history))\n",
        "  return yhat[0]\n",
        "\n",
        "# split a univariate dataset into train/test sets\n",
        "def train_test_split(data, n_test):\n",
        "\treturn data[:-n_test], data[-n_test:]\n",
        "\n",
        "# root mean squared error or rmse\n",
        "def measure_rmse(actual, predicted):\n",
        "\treturn sqrt(mean_squared_error(actual, predicted))\n",
        "\n",
        "# walk-forward validation for univariate data\n",
        "def walk_forward_validation(data, n_test, cfg):\n",
        "  predictions = list()\n",
        "\t# split dataset\n",
        "  train, test = train_test_split(data, n_test)\n",
        "\t# seed history with training dataset\n",
        "  history = [x for x in train]\n",
        "\t# step over each time-step in the test set\n",
        "  for i in range(len(test)):\n",
        "\t\t# fit model and make forecast for history\n",
        "    yhat = sarima_forecast(history, cfg)\n",
        "\t\t# store forecast in list of predictions\n",
        "    predictions.append(yhat)\n",
        "\t\t# add actual observation to history for the next loop\n",
        "    history.append(test[i])\n",
        "\t# estimate prediction error\n",
        "  error = measure_rmse(test, predictions)\n",
        "  return error\n",
        "\n",
        "# score a model, return None on failure\n",
        "@techila.distributable()\n",
        "def score_model(data, n_test, cfg, debug=False):\n",
        "  result = None\n",
        "\t# convert config to a key\n",
        "  key = str(cfg)\n",
        "\n",
        "\t# show all warnings and fail on exception if debugging\n",
        "  if debug:\n",
        "    result = walk_forward_validation(data, n_test, cfg)\n",
        "  else:\n",
        "\t\t# one failure during model validation suggests an unstable config\n",
        "    try:\n",
        "\t\t\t# never show warnings when grid searching, too noisy\n",
        "      with catch_warnings():\n",
        "        filterwarnings(\"ignore\")\n",
        "        result = walk_forward_validation(data, n_test, cfg)\n",
        "    except:\n",
        "      error = None\n",
        "\t# check for an interesting result\n",
        "  #if result is not None:\n",
        "  #  print(' > Model[%s] %.3f' % (key, result))\n",
        "  return (key, result)\n",
        "\n",
        "# grid search configs\n",
        "def grid_search(data, cfg_list, n_test, parallel=True):\n",
        "  scores = None\n",
        "  result = []\n",
        "  for cfg in cfg_list:\n",
        "    result.append(score_model(data, n_test, cfg))\n",
        "\n",
        "  if parallel:\n",
        "    techila.run(steps=num_of_operations_per_parallel_job)\n",
        "    scores = [x.result for x in result]\n",
        "  else:\n",
        "    scores = [x for x in result]\n",
        "    \n",
        "  # remove empty results\n",
        "  scores = [r for r in scores if r[1] != None]\n",
        "  # sort configs by error, asc\n",
        "  scores.sort(key=lambda tup: tup[1])\n",
        "  return scores\n",
        "\n",
        "print (\"Ready.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF_lIC6yXNEg",
        "colab_type": "text"
      },
      "source": [
        "## Search the Top #3 Hyperparameter candidates\n",
        "Use these parameters to run your forecasts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_7euyuAbLhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do data splitting\n",
        "n_test = round(len(data) * n_test_percentage)\n",
        "# Load model configudations\n",
        "cfg_list = sarima_configs()\n",
        "\n",
        "# Run grid search\n",
        "scores = grid_search(data, cfg_list, n_test, run_parallel)\n",
        "\n",
        "# Show the top 3 hyperparameter configudations\n",
        "print(\"Top #3 Hyperparameter candidates:\")\n",
        "for cfg, error in scores[:3]:\n",
        "  print(cfg, error)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
